### 哈希槽案例实战：spring集成redis集群哈希槽

#### 步骤1：改集群配置
只改集群配置就行，其他都不用改 
``` 
spring.application.name=spring-boot-redis
server.port=9090


# 为某个包目录下 设置日志
logging.level.com.agan=debug
logging.level.io.lettuce=debug

#表示是否开启 Swagger，一般线上环境是关闭的
spring.swagger2.enabled=true



## Redis 配置
## Redis数据库索引（默认为0）
spring.redis.database=1
## Redis服务器地址
#spring.redis.host=127.0.0.1
## Redis服务器连接端口
#spring.redis.port=4637
## Redis服务器连接密码（默认为空）
#spring.redis.password=agan
## 连接池最大连接数（使用负值表示没有限制）
spring.redis.lettuce.pool.max-active=8
## 连接池中的最大空闲连接
spring.redis.lettuce.pool.max-idle=8
## 连接池最大阻塞等待时间（使用负值表示没有限制）
spring.redis.lettuce.pool.max-wait=-1ms
## 连接池中的最小空闲连接
spring.redis.lettuce.pool.min-idle=0
#spring.redis.sentinel.master= # Name of Redis server.
#spring.redis.sentinel.nodes= # Comma-separated list of host:port pairs.
spring.redis.timeout=1m
spring.redis.cluster.nodes=192.168.1.138:6381,192.168.1.138:6382

```
#### 步骤2：加10条数据进集群
``` 
@GetMapping(value = "/init")
public void refreshData(){
    for (int i=0;i<10;i++){
        String key="user:"+i;
        this.redisTemplate.opsForValue().set(key,i);
        log.debug("set key={},value={}",key,i);
    }
}
```



### 3.做试验


### 验证数据是否被切分成3份
所有数据会被分成3份，存在3个主里面。我们进入 6381 和6382看里面的数据是否不一样
docker exec -it redis-node-1 /bin/bash
redis-cli -h 192.168.1.138 -p 6381 -c

```
root@node2:/data# redis-cli -h 192.168.1.138 -p 6381 -c
192.168.1.138:6381> keys *
1) "user:7"
2) "user:9"
3) "user:3"
4) "user:2"
192.168.1.138:6381>
root@node2:/data# redis-cli -h 192.168.1.138 -p 6382 -c
192.168.1.138:6382> keys *
1) "user:6"
2) "user:100"
3) "user:5"
4) "user:1"
192.168.1.138:6382>
root@node2:/data# redis-cli -h 192.168.1.138 -p 6383 -c
192.168.1.138:6383> keys *
1) "user:200"
2) "user:8"
3) "user:4"
4) "user:0"
```
### 验证数据主从的数据是否一样
看 192.168.1.138:6386 和 192.168.1.138:6381的数据是否一样 
``` 
root@node2:/data# redis-cli -h 192.168.1.138 -p 6381 -c
192.168.1.138:6381> keys *
1) "user:7"
2) "user:9"
3) "user:3"
4) "user:2"
192.168.1.138:6381>
root@node2:/data# redis-cli -h 192.168.1.138 -p 6386 -c
192.168.1.138:6386> keys *
1) "user:2"
2) "user:9"
3) "user:7"
4) "user:3"
```

以上数据虽然是被打乱了，但是仔细看，他们的数据都是一样的哦。


结论：
1.redis的集群读写操作，数据都会被切成3份，放在不同的master里面
2.redis的主从，里面的数据一定是一样的。


